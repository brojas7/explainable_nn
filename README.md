# Explainable Neural Network (XNN)

Una librerÃ­a de Python diseÃ±ada para construir, entrenar y explicar redes neuronales **desde cero**, con soporte para **explicabilidad estructural** (rutas internas, activaciones, contribuciones por neurona) y explicaciones en **lenguaje natural** mediante **Gemini**.

Este paquete es ideal para:
- Cursos de IA y ciencia de datos
- Proyectos que requieren interpretabilidad
- Investigaciones en modelos explicables
- IntegraciÃ³n con sistemas reales que necesiten auditabilidad

---

## CaracterÃ­sticas Principales

### âœ” Red neuronal implementada **desde cero**
- Forward y backward propagation manuales
- InicializaciÃ³n Xavier
- Funciones de activaciÃ³n ReLU y softmax
- CÃ¡lculo explÃ­cito de gradientes

### âœ” Explicabilidad profunda (XAI integrada)
- Registro de activaciones y preactivaciones por capa
- ExtracciÃ³n de la *ruta principal* de contribuciÃ³n
- Desglose cuantitativo por neurona
- Log tÃ©cnico completo

### âœ” ExplicaciÃ³n en lenguaje natural con Gemini
- Resumen amigable de decisiones internas
- AnÃ¡lisis basado en activaciones, logits y pesos
- Personalizable con contexto de negocio y de variables

### âœ” Pipeline listo para producciÃ³n
- Guardado y carga con `dill`
- FunciÃ³n genÃ©rica `predict_with_explanation()`
- IntegraciÃ³n modular con scalers
- DiseÃ±o limpio, desacoplado y extensible

---

## ğŸ“¦ InstalaciÃ³n

Clonar el repositorio en tu entorno:

```bash
git clone https://github.com/brojas7/explainable_nn.git
cd explainable_nn
pip install -e .
```

---

## ğŸ“ Estructura del Proyecto

```text
explainable_nn/
â”‚
â”œâ”€â”€ explainable_nn/            # CÃ³digo fuente del paquete
â”‚   â”œâ”€â”€ core.py                # Red neuronal + explicabilidad
â”‚   â”œâ”€â”€ gemini_wrapper.py      # Wrapper para LLM de Gemini
â”‚   â”œâ”€â”€ utils.py               # Guardado y carga de modelos
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ examples/                  # Ejemplos prÃ¡cticos
â”‚   â””â”€â”€ demo_iris.py           # Demo con dataset Iris
â”‚
â”œâ”€â”€ tests/                     # Pruebas unitarias
â”‚   â””â”€â”€ test_basic.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ setup.py
```

---

## ğŸ”§ Uso RÃ¡pido

### 1. Entrenamiento de una red neuronal

```python
from explainable_nn.core import ExplainableNeuralNet
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

iris = load_iris()
X = iris.data
y = iris.target

scaler = StandardScaler()
X = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)

nn = ExplainableNeuralNet([4,6,6,3], learning_rate=0.02)

for epoch in range(300):
    for xi, yi in zip(X_train, y_train):
        nn.train_step(xi, yi)
```

---

### 2. Guardar el modelo entrenado

```python
from explainable_nn.utils import save_model
save_model("modelo.pkl", nn, scaler)
```

---

### 3. Cargar y realizar una predicciÃ³n explicable

```python
from explainable_nn.utils import load_model
from explainable_nn.core import predict_with_explanation

saved = load_model("modelo.pkl")
nn2 = saved["modelo"]
scaler2 = saved["scaler"]

nuevo = [5.1, 3.8, 1.6, 0.2]

log, explicacion = predict_with_explanation(nn2, nuevo, scaler=scaler2)
print(log)
```

---

## 4. ExplicaciÃ³n con Gemini

```python
from explainable_nn.gemini_wrapper import NeuralExplainerLLM

API_KEY = "TU_API_KEY"
explainer = NeuralExplainerLLM(api_key=API_KEY)

feature_context = {
    "0": "Longitud del sÃ©palo (cm)",
    "1": "Ancho del sÃ©palo (cm)",
    "2": "Longitud del pÃ©talo (cm)",
    "3": "Ancho del pÃ©talo (cm)"
}

business_context = """
0 = Setosa
1 = Versicolor
2 = Virginica
"""

log, natural = predict_with_explanation(
    model=nn2,
    x_input=nuevo,
    scaler=scaler2,
    llm=explainer,
    feature_context=feature_context,
    business_context=business_context
)

print(natural)
```

---

##  EjecuciÃ³n en Google Colab
[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1jT2KGJKl1UY4QF9pAPD9YFGKSaHlqGii?usp=sharing)


```python
!git clone https://github.com/brojas7/explainable_nn.git
%cd explainable_nn
!pip install -e .
```

Y luego puedes ejecutar los ejemplos desde:

```python
%run examples/demo_iris.py
```

---

## Roadmap Futuro

- ImplementaciÃ³n modular de capas (Dense, Dropout, Normalization)
- MÃ©tricas avanzadas de explicabilidad (SHAP, LIME, Integrated Gradients)
- Visualizaciones automÃ¡ticas de rutas explicables
- ImplementaciÃ³n GPU opcional

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo **MIT License**.
Puedes usarlo libremente en proyectos personales, acadÃ©micos y comerciales.

---

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Puedes abrir:
- Issues
- Pull Requests
- Mejoras en documentaciÃ³n
- Nuevos ejemplos o datasets

---

## ğŸ‘¤ Autor
**Bernal Rojas**
Profesor, Universidad Cenfotec


